╔══════════════════════════════════════════════════════════════════════════════════════════════════════════════════════╗
║                                    HYBRID DEEPFAKE DETECTION - TAM AKIŞ DİYAGRAMI                                    ║
║                                              (WavLM + SSPS Hybrid Model)                                             ║
╚══════════════════════════════════════════════════════════════════════════════════════════════════════════════════════╝

═══════════════════════════════════════════════════════════════════════════════════════════════════════════════════════
                                              AŞAMA 1: FEATURE EXTRACTION
═══════════════════════════════════════════════════════════════════════════════════════════════════════════════════════

                                    ┌─────────────────────────────────────┐
                                    │         RAW AUDIO (.flac)           │
                                    │        (16kHz, ~15 saniye)          │
                                    │          ~240,000 sample            │
                                    └──────────────┬──────────────────────┘
                                                   │
                           ┌───────────────────────┼───────────────────────┐
                           │                       │                       │
                           ▼                       │                       ▼
    ┌──────────────────────────────────────┐       │       ┌──────────────────────────────────────┐
    │       WAVLM FEATURE EXTRACTION       │       │       │       SSPS FEATURE EXTRACTION        │
    │       (extract_wavlm.py)             │       │       │    (extractFeatures_SSPS_simple.py)  │
    └──────────────────────────────────────┘       │       └──────────────────────────────────────┘
                           │                       │                       │
                           ▼                       │                       ▼
    ┌──────────────────────────────────────┐       │       ┌──────────────────────────────────────┐
    │   1. torchaudio.pipelines.WAVLM_LARGE│       │       │   1. MelSpectrogram (40 mels)        │
    │      Pre-trained model (94K hours)   │       │       │      (B, 40, T)                      │
    └──────────────────────────────────────┘       │       └──────────────────────────────────────┘
                           │                       │                       │
                           ▼                       │                       ▼
    ┌──────────────────────────────────────┐       │       ┌──────────────────────────────────────┐
    │   2. Forward Pass (tüm katmanlar)    │       │       │   2. TDNNBlock (ilk katman)          │
    │      features, _ = model.extract_    │       │       │      (B, 1024, T)                    │
    │                     features(wav)    │       │       └──────────────────────────────────────┘
    │      shape: (25 layers, B, T', 1024) │       │                       │
    └──────────────────────────────────────┘       │                       ▼
                           │                       │       ┌──────────────────────────────────────┐
                           ▼                       │       │   3. SERes2NetBlock x4               │
    ┌──────────────────────────────────────┐       │       │      (dilation: 2,3,4,1)             │
    │   3. Layer 8 Seçimi                  │       │       │      (B, 1024, T) each               │
    │      layer_8 = features[8]           │       │       └──────────────────────────────────────┘
    │      shape: (B, T', 1024)            │       │                       │
    └──────────────────────────────────────┘       │                       ▼
                           │                       │       ┌──────────────────────────────────────┐
                           ▼                       │       │   4. Multi-Frame Aggregation (MFA)   │
    ┌──────────────────────────────────────┐       │       │      concat(layer2, layer3, layer4)  │
    │   4. Transpose                       │       │       │      (B, 3072, T)                    │
    │      (B, T', 1024) → (B, 1024, T')   │       │       └──────────────────────────────────────┘
    │      T' ≈ 750 frames                 │       │                       │
    └──────────────────────────────────────┘       │                       ▼
                           │                       │       ┌──────────────────────────────────────┐
                           ▼                       │       │   5. Attentive Statistics Pooling    │
    ┌──────────────────────────────────────┐       │       │      (ASP) - Temporal → 1            │
    │   5. 4x Downsample                   │       │       │      mean + std: (B, 6144, 1)        │
    │      output = output[:, ::4]         │       │       └──────────────────────────────────────┘
    │      (B, 1024, 750) → (B, 1024, 187) │       │                       │
    └──────────────────────────────────────┘       │                       ▼
                           │                       │       ┌──────────────────────────────────────┐
                           ▼                       │       │   6. BatchNorm + FC Layer            │
    ┌──────────────────────────────────────┐       │       │      (B, 6144, 1) → (B, 512, 1)      │
    │   6. Float16 Dönüşümü                │       │       │      squeeze → (B, 512)              │
    │      output = output.half()          │       │       └──────────────────────────────────────┘
    │      float32 → float16 (50% tasarruf)│       │                       │
    └──────────────────────────────────────┘       │                       ▼
                           │                       │       ┌──────────────────────────────────────┐
                           ▼                       │       │   7. L2 Normalize                    │
    ┌──────────────────────────────────────┐       │       │      embedding = F.normalize(x)      │
    │   7. Kaydet                          │       │       │      shape: (512,)                   │
    │      torch.save(output, "X.pt")      │       │       └──────────────────────────────────────┘
    │                                      │       │                       │
    │      Output: (1024, 187) tensor      │       │                       ▼
    │      Dosya boyutu: ~380 KB           │       │       ┌──────────────────────────────────────┐
    └──────────────────────────────────────┘       │       │   8. Kaydet                          │
                           │                       │       │      torch.save(emb, "X.pt")         │
                           │                       │       │                                      │
                           │                       │       │      Output: (512,) tensor           │
                           │                       │       │      Dosya boyutu: ~2 KB             │
                           │                       │       └──────────────────────────────────────┘
                           │                       │                       │
                           ▼                       │                       ▼
    ┌──────────────────────────────────────┐       │       ┌──────────────────────────────────────┐
    │  WAVLM_LARGE_L8_ds4_fp16/            │       │       │  SSPS_SimCLR_ECAPA/                  │
    │  ├── train/ (~18K files, ~7GB)       │       │       │  ├── train/ (~18K files, ~35MB)      │
    │  ├── dev/   (~31K files, ~12GB)      │       │       │  ├── dev/   (~31K files, ~60MB)      │
    │  └── eval/  (~680K files, ~110GB)    │       │       │  └── eval/  (~680K files, ~1.3GB)    │
    │                                      │       │       │                                      │
    │  TOPLAM: ~130 GB                     │       │       │  TOPLAM: ~1.5 GB                     │
    └──────────────────────────────────────┘       │       └──────────────────────────────────────┘
                           │                       │                       │
                           └───────────────────────┼───────────────────────┘
                                                   │
                                                   ▼
                              ┌─────────────────────────────────────────────┐
                              │           FEATURE FILES HAZIR               │
                              │     WavLM: (1024, 187) per utterance        │
                              │     SSPS: (512,) per utterance              │
                              └─────────────────────────────────────────────┘


═══════════════════════════════════════════════════════════════════════════════════════════════════════════════════════
                                              AŞAMA 2: DATASET LOADING
═══════════════════════════════════════════════════════════════════════════════════════════════════════════════════════

                              ┌─────────────────────────────────────────────┐
                              │           HybridFeatureDataset              │
                              │              (train_hybrid.py)              │
                              └─────────────────────────────────────────────┘
                                                   │
                   ┌───────────────────────────────┼───────────────────────────────┐
                   │                               │                               │
                   ▼                               ▼                               ▼
    ┌──────────────────────────┐    ┌──────────────────────────┐    ┌──────────────────────────┐
    │   Protocol File Parse    │    │   WavLM Feature Load     │    │   SSPS Feature Load      │
    │   ASVspoof5.train.tsv    │    │                          │    │                          │
    └──────────────────────────┘    └──────────────────────────┘    └──────────────────────────┘
                   │                               │                               │
                   ▼                               ▼                               ▼
    ┌──────────────────────────┐    ┌──────────────────────────┐    ┌──────────────────────────┐
    │   _guess_uid_index()     │    │   torch.load("X.pt")     │    │   torch.load("X.pt")     │
    │   Pattern: T_0000000001  │    │   shape: (1024, 187)     │    │   shape: (512,)          │
    │                          │    │                          │    │                          │
    │   _guess_label_index()   │    │   float16 → float32      │    │   float32 (already)      │
    │   "bonafide" or "spoof"  │    │                          │    │                          │
    └──────────────────────────┘    └──────────────────────────┘    └──────────────────────────┘
                   │                               │                               │
                   │                               ▼                               │
                   │                ┌──────────────────────────┐                   │
                   │                │   _pad() Function        │                   │
                   │                │   T < 187: repeat pad    │                   │
                   │                │   T > 187: truncate      │                   │
                   │                │   output: (1024, 187)    │                   │
                   │                └──────────────────────────┘                   │
                   │                               │                               │
                   └───────────────────────────────┼───────────────────────────────┘
                                                   │
                                                   ▼
                              ┌─────────────────────────────────────────────┐
                              │              __getitem__ Output             │
                              │   return (wavlm, ssps, utt_id, label)       │
                              │          (1024,187), (512,), str, int       │
                              └─────────────────────────────────────────────┘
                                                   │
                                                   ▼
                              ┌─────────────────────────────────────────────┐
                              │              DataLoader Batch               │
                              │   wavlm: (B, 1024, 187)                     │
                              │   ssps:  (B, 512)                           │
                              │   uids:  [str] x B                          │
                              │   labels: (B,) - 0=bonafide, 1=spoof        │
                              │                                             │
                              │   B = 64 (batch_size)                       │
                              └─────────────────────────────────────────────┘


═══════════════════════════════════════════════════════════════════════════════════════════════════════════════════════
                                              AŞAMA 3: MODEL FORWARD PASS
═══════════════════════════════════════════════════════════════════════════════════════════════════════════════════════

                              ┌─────────────────────────────────────────────┐
                              │              HybridModel                    │
                              │           (train_hybrid.py)                 │
                              └─────────────────────────────────────────────┘
                                                   │
                                    ┌──────────────┴──────────────┐
                                    │                             │
                                    ▼                             ▼
                   ┌────────────────────────────┐   ┌────────────────────────────┐
                   │      WavLM Branch          │   │      SSPS Branch           │
                   │      Input: (B, 1024, 187) │   │      Input: (B, 512)       │
                   └────────────────────────────┘   └────────────────────────────┘
                                    │                             │
                                    ▼                             ▼
                   ┌────────────────────────────┐   ┌────────────────────────────┐
                   │ NeXt-TDNN Backbone         │   │ ssps_fc = Sequential(      │
                   │ (NeXt_TDNN_ECA_ilk_ilk_    │   │   Linear(512, 256),        │
                   │          Light)            │   │   BatchNorm1d(256),        │
                   │                            │   │   ReLU()                   │
                   │ Temporal modeling:         │   │ )                          │
                   │ - Conv1D blocks            │   │                            │
                   │ - ECA attention            │   │ Output: (B, 256)           │
                   │ - Residual connections     │   │                            │
                   │                            │   │                            │
                   │ Output: (B, C', T')        │   │                            │
                   └────────────────────────────┘   └────────────────────────────┘
                                    │                             │
                                    ▼                             │
                   ┌────────────────────────────┐                 │
                   │ AdaptiveAvgPool1d(1)       │                 │
                   │ (B, C', T') → (B, C', 1)   │                 │
                   │ squeeze → (B, C')          │                 │
                   └────────────────────────────┘                 │
                                    │                             │
                                    ▼                             │
                   ┌────────────────────────────┐                 │
                   │ wavlm_fc = Linear(C', 256) │                 │
                   │ Output: (B, 256)           │                 │
                   └────────────────────────────┘                 │
                                    │                             │
                                    │     w_emb: (B, 256)         │    s_emb: (B, 256)
                                    │                             │
                                    └──────────────┬──────────────┘
                                                   │
                                                   ▼
                              ┌─────────────────────────────────────────────┐
                              │            ATTENTION FUSION                 │
                              │                                             │
                              │   concat = torch.cat([w_emb, s_emb], dim=-1)│
                              │   shape: (B, 512)                           │
                              │                                             │
                              │   attention = Sequential(                   │
                              │     Linear(512, 256),                       │
                              │     Tanh(),                                 │
                              │     Linear(256, 2),                         │
                              │     Softmax(dim=-1)                         │
                              │   )                                         │
                              │                                             │
                              │   attn_weights = attention(concat)          │
                              │   shape: (B, 2) → [α, β]                    │
                              │                                             │
                              │   α + β = 1 (softmax garantisi)             │
                              │                                             │
                              │   fused = α * w_emb + β * s_emb             │
                              │   shape: (B, 256)                           │
                              └─────────────────────────────────────────────┘
                                                   │
                                    ┌──────────────┴──────────────┐
                                    │                             │
                                    ▼                             ▼
                   ┌────────────────────────────┐   ┌────────────────────────────┐
                   │   L2 Normalization         │   │   Classifier               │
                   │   emb = F.normalize(fused) │   │   Sequential(              │
                   │   shape: (B, 256)          │   │     Linear(256, 256),      │
                   │                            │   │     BatchNorm1d(256),      │
                   │   ||emb|| = 1              │   │     ReLU(),                │
                   │   (unit hypersphere)       │   │     Dropout(0.3),          │
                   │                            │   │     Linear(256, 2)         │
                   │                            │   │   )                        │
                   │                            │   │   Output: (B, 2)           │
                   └────────────────────────────┘   └────────────────────────────┘
                                    │                             │
                                    │                             │
                                    ▼                             ▼
                              ┌─────────────────────────────────────────────┐
                              │              MODEL OUTPUT                   │
                              │                                             │
                              │   return emb, logits                        │
                              │          (B, 256), (B, 2)                   │
                              │                                             │
                              │   emb: OC-Softmax için (normalize edilmiş)  │
                              │   logits: CE loss için (raw scores)         │
                              └─────────────────────────────────────────────┘


═══════════════════════════════════════════════════════════════════════════════════════════════════════════════════════
                                              AŞAMA 4: LOSS HESAPLAMA
═══════════════════════════════════════════════════════════════════════════════════════════════════════════════════════

                              ┌─────────────────────────────────────────────┐
                              │              OC-Softmax Loss                │
                              │             (loss/ocsoftmax.py)             │
                              │                                             │
                              │   Parameters:                               │
                              │   - center: (1, 256) learnable              │
                              │   - r_real: 0.9 (bonafide margin)           │
                              │   - r_fake: 0.2 (spoof margin)              │
                              │   - alpha: 20.0 (scale factor)              │
                              └─────────────────────────────────────────────┘
                                                   │
                                                   ▼
                              ┌─────────────────────────────────────────────┐
                              │            FORWARD PASS                     │
                              │                                             │
                              │   1. w = F.normalize(center, dim=1)         │
                              │      shape: (1, 256)                        │
                              │                                             │
                              │   2. scores = emb @ w.T                     │
                              │      shape: (B, 1)                          │
                              │      range: [-1, 1] (cosine similarity)     │
                              │                                             │
                              │   3. Loss hesaplama:                        │
                              │      bonafide (label=0):                    │
                              │        loss = α * (r_real - score)          │
                              │        Hedef: score → r_real (0.9)          │
                              │                                             │
                              │      spoof (label=1):                       │
                              │        loss = α * (score - r_fake)          │
                              │        Hedef: score → r_fake (0.2)          │
                              │                                             │
                              │   4. output_logits için:                    │
                              │      logits[:, 0] = α * (score - r_fake)    │
                              │      logits[:, 1] = α * (r_real - score)    │
                              └─────────────────────────────────────────────┘
                                                   │
                                                   ▼
                              ┌─────────────────────────────────────────────┐
                              │            LOSS OUTPUT                      │
                              │                                             │
                              │   return loss, output_logits                │
                              │          scalar, (B, 2)                     │
                              │                                             │
                              │   loss: Backprop için                       │
                              │   output_logits: Validation için            │
                              └─────────────────────────────────────────────┘


═══════════════════════════════════════════════════════════════════════════════════════════════════════════════════════
                                              AŞAMA 5: TRAINING LOOP
═══════════════════════════════════════════════════════════════════════════════════════════════════════════════════════

                              ┌─────────────────────────────────────────────┐
                              │              TRAINING LOOP                  │
                              │              (100 epochs max)               │
                              └─────────────────────────────────────────────┘
                                                   │
                                                   ▼
    ┌──────────────────────────────────────────────────────────────────────────────────────────────────────────┐
    │                                         FOR EACH EPOCH                                                   │
    │  ┌────────────────────────────────────────────────────────────────────────────────────────────────────┐  │
    │  │                                                                                                    │  │
    │  │   1. Learning Rate Adjust                                                                          │  │
    │  │      lr = 1e-4 * (0.5 ^ (epoch // 20))                                                             │  │
    │  │      Epoch 0-19: lr=1e-4                                                                           │  │
    │  │      Epoch 20-39: lr=5e-5                                                                          │  │
    │  │      Epoch 40-59: lr=2.5e-5                                                                        │  │
    │  │      ...                                                                                           │  │
    │  │                                                                                                    │  │
    │  │   2. Train Phase (model.train())                                                                   │  │
    │  │      FOR EACH BATCH (284 batches = 18,176 / 64):                                                   │  │
    │  │      ┌─────────────────────────────────────────────────────────────────────────────────────────┐   │  │
    │  │      │  a. Forward:  emb, logits = model(wavlm, ssps)                                          │   │  │
    │  │      │  b. Loss:     loss, _ = ocsoftmax(emb, labels)                                          │   │  │
    │  │      │  c. Backward: loss.backward()                                                           │   │  │
    │  │      │  d. Clip:     clip_grad_norm_(model.parameters(), max_norm=1.0)                         │   │  │
    │  │      │  e. Step:     optimizer.step()                                                          │   │  │
    │  │      └─────────────────────────────────────────────────────────────────────────────────────────┘   │  │
    │  │                                                                                                    │  │
    │  │   3. Validation Phase (model.eval())                                                               │  │
    │  │      FOR EACH BATCH (487 batches = 31,174 / 64):                                                   │  │
    │  │      ┌─────────────────────────────────────────────────────────────────────────────────────────┐   │  │
    │  │      │  a. with torch.no_grad():                                                               │   │  │
    │  │      │  b. emb, logits = model(wavlm, ssps)                                                    │   │  │
    │  │      │  c. _, logits = ocsoftmax(emb, labels)                                                  │   │  │
    │  │      │  d. scores = softmax(logits)[:, 0]  # bonafide prob                                     │   │  │
    │  │      │  e. Collect scores and labels                                                           │   │  │
    │  │      └─────────────────────────────────────────────────────────────────────────────────────────┘   │  │
    │  │                                                                                                    │  │
    │  │   4. EER Hesaplama                                                                                 │  │
    │  │      bonafide_scores = scores[labels == 0]                                                         │  │
    │  │      spoof_scores = scores[labels == 1]                                                            │  │
    │  │      eer = compute_eer(bonafide_scores, spoof_scores)                                              │  │
    │  │                                                                                                    │  │
    │  │   5. Checkpoint & Early Stopping                                                                   │  │
    │  │      if eer < best_eer:                                                                            │  │
    │  │          save_checkpoint(model, "anti-spoofing_model.pt")                                          │  │
    │  │          best_eer = eer                                                                            │  │
    │  │          patience_counter = 0                                                                      │  │
    │  │      else:                                                                                         │  │
    │  │          patience_counter += 1                                                                     │  │
    │  │          if patience_counter >= 20:                                                                │  │
    │  │              STOP                                                                                  │  │
    │  │                                                                                                    │  │
    │  └────────────────────────────────────────────────────────────────────────────────────────────────────┘  │
    └──────────────────────────────────────────────────────────────────────────────────────────────────────────┘
                                                      │
                                                      ▼
                              ┌─────────────────────────────────────────────┐
                              │           TRAINING COMPLETE                 │
                              │                                             │
                              │   Output Files:                             │
                              │   - anti-spoofing_model.pt (best model)     │
                              │   - anti-spoofing_loss_model.pt (OC center) │
                              │   - eer.log (epoch log)                     │
                              │   - checkpoint/ (all epochs)                │
                              │                                             │
                              │   Best Dev EER: ~3.5%                       │
                              └─────────────────────────────────────────────┘


═══════════════════════════════════════════════════════════════════════════════════════════════════════════════════════
                                              AŞAMA 6: INFERENCE (TEST)
═══════════════════════════════════════════════════════════════════════════════════════════════════════════════════════

                              ┌─────────────────────────────────────────────┐
                              │              test_hybrid.py                 │
                              │              (Eval Phase)                   │
                              └─────────────────────────────────────────────┘
                                                   │
                                                   ▼
                              ┌─────────────────────────────────────────────┐
                              │            LOAD TRAINED MODEL               │
                              │                                             │
                              │   model.load_state_dict(checkpoint)         │
                              │   ocsoftmax.load_state_dict(loss_model)     │
                              │   model.eval()                              │
                              └─────────────────────────────────────────────┘
                                                   │
                                                   ▼
    ┌──────────────────────────────────────────────────────────────────────────────────────────────────────────┐
    │                                      FOR EACH EVAL SAMPLE (680,774)                                      │
    │                                                                                                          │
    │   ┌───────────────────────┐    ┌───────────────────────┐    ┌───────────────────────┐                    │
    │   │  Load WavLM Feature   │    │  Load SSPS Feature    │    │  Forward Pass         │                    │
    │   │  (1024, 187)          │ →  │  (512,)               │ →  │  emb, _ = model(w, s) │                    │
    │   └───────────────────────┘    └───────────────────────┘    └───────────────────────┘                    │
    │                                                                         │                                │
    │                                                                         ▼                                │
    │                                              ┌─────────────────────────────────────────────┐             │
    │                                              │   Score Calculation                         │             │
    │                                              │                                             │             │
    │                                              │   center = ocsoftmax.center  # (1, 256)     │             │
    │                                              │   w = F.normalize(center)                   │             │
    │                                              │   score = emb @ w.T  # [-1, 1]              │             │
    │                                              │                                             │             │
    │                                              │   Yüksek score → Bonafide                   │             │
    │                                              │   Düşük score → Spoof                       │             │
    │                                              └─────────────────────────────────────────────┘             │
    │                                                                         │                                │
    │                                                                         ▼                                │
    │                                              ┌─────────────────────────────────────────────┐             │
    │                                              │   Save Score                                │             │
    │                                              │   f.write(f"{utt_id}\t{score}\t{label}")    │             │
    │                                              └─────────────────────────────────────────────┘             │
    └──────────────────────────────────────────────────────────────────────────────────────────────────────────┘
                                                   │
                                                   ▼
                              ┌─────────────────────────────────────────────┐
                              │              EER CALCULATION                │
                              │                                             │
                              │   bonafide_scores = scores[label == 0]      │
                              │   # ~138,688 samples                        │
                              │                                             │
                              │   spoof_scores = scores[label == 1]         │
                              │   # ~542,086 samples                        │
                              │                                             │
                              │   eer, threshold = compute_eer(             │
                              │       bonafide_scores, spoof_scores         │
                              │   )                                         │
                              │                                             │
                              │   EVAL EER: 5.37%                           │
                              │   minDCF: 0.2443                            │
                              └─────────────────────────────────────────────┘


═══════════════════════════════════════════════════════════════════════════════════════════════════════════════════════
                                              ÖZET: KARAR MEKANIZMASI
═══════════════════════════════════════════════════════════════════════════════════════════════════════════════════════

                              ┌─────────────────────────────────────────────┐
                              │           FINAL DECISION FLOW               │
                              └─────────────────────────────────────────────┘

    ┌──────────────────┐     ┌──────────────────┐     ┌──────────────────┐     ┌─────────────────┐
    │   Raw Audio      │ ──▶ │   WavLM         │ ──▶ │   NeXt-TDNN      │ ──▶ │   256-D emb    │
    │   (.flac)        │     │   Layer 8        │     │   Backbone       │     │   (w_emb)       │
    │                  │     │   (1024, 187)    │     │                  │     │                 │
    └──────────────────┘     └──────────────────┘     └──────────────────┘     └───────┬─────────┘
           │                                                                           │
           │                                                                           │
           │                 ┌──────────────────┐     ┌──────────────────┐             │    ┌──────────────────┐
           └───────────────▶ │   SSPS          │ ──▶ │   FC + BN + ReLU │ ──▶────────┴───▶│   ATTENTION      │
                             │   ECAPA-TDNN     │     │   (512 → 256)    │                  │   FUSION         │
                             │   (512,)         │     │   (s_emb)        │                  │                  │
                             └──────────────────┘     └──────────────────┘                  │   α*w + β*s      │
                                                                                            │   (256-D fused)  │
                                                                                            └────────┬─────────┘
                                                                                                    │
                                                                                                    ▼
                                                                              ┌─────────────────────────────────────┐
                                                                              │   L2 NORMALIZE                      │
                                                                              │   emb = fused / ||fused||           │
                                                                              │   (unit sphere)                     │
                                                                              └────────────────┬────────────────────┘
                                                                                               │
                                                                                               ▼
                                                                              ┌─────────────────────────────────────┐
                                                                              │   COSINE SIMILARITY                 │
                                                                              │   score = emb · center              │
                                                                              │   range: [-1, +1]                   │
                                                                              └────────────────┬────────────────────┘
                                                                                               │
                                                                                               ▼
                                                                              ┌─────────────────────────────────────┐
                                                                              │   DECISION                          │
                                                                              │                                     │
                                                                              │   score > threshold → BONAFIDE      │
                                                                              │   score < threshold → SPOOF         │
                                                                              │                                     │
                                                                              │   Threshold @ EER: ~0.55            │
                                                                              └─────────────────────────────────────┘


═══════════════════════════════════════════════════════════════════════════════════════════════════════════════════════
                                              DOSYA YAPISI ÖZET
═══════════════════════════════════════════════════════════════════════════════════════════════════════════════════════

Deepfake-audio-detection-SSLFeatures-NextTDNN-main/
├── config.py                          # Konfigürasyon (paths, hyperparams)
├── train_hybrid.py                    # Training script
├── test_hybrid.py                     # Testing script
├── extract_wavlm.py                   # WavLM feature extraction
├── extractFeatures_SSPS_simple.py     # SSPS feature extraction
├── eval_metrics.py                    # EER, minDCF hesaplama
├── loss/
│   └── ocsoftmax.py                   # OC-Softmax loss
├── NeXt_TDNN_ASV/
│   └── models/
│       └── NeXt_TDNN_ECA_ilk_ilk_Light.py  # Backbone model
└── models/
    └── hybrid_wavlm_ds4_fp16_ssps/
        ├── anti-spoofing_model.pt     # Best model weights
        ├── anti-spoofing_loss_model.pt # OC-Softmax center
        ├── eval_scores.txt            # Eval sonuçları
        └── eer.log                    # Training log

Asvspoof5/asvspoof5/
├── features/
│   ├── WAVLM_LARGE_L8_ds4_fp16/       # WavLM features (~130GB)
│   │   ├── train/ (~18K files)
│   │   ├── dev/   (~31K files)
│   │   └── eval/  (~680K files)
│   └── SSPS_SimCLR_ECAPA/             # SSPS features (~1.5GB)
│       ├── train/
│       ├── dev/
│       └── eval/
├── ASVspoof5.train.tsv                # Train protokolü
├── ASVspoof5.dev.track_1.tsv          # Dev protokolü
└── ASVspoof5.eval.track_1.tsv         # Eval protokolü

═══════════════════════════════════════════════════════════════════════════════════════════════════════════════════════
                                              SONUÇLAR
═══════════════════════════════════════════════════════════════════════════════════════════════════════════════════════

┌───────────────────────────────────────────────────────────────────────────────────────────────────────────────────┐
│                                                                                                                   │
│   MODEL: WavLM (4x DS, fp16) + SSPS Hybrid                                                                        │
│                                                                                                                   │
│   ┌─────────────────────────────┬─────────────────────────────┬─────────────────────────────┐                     │
│   │         Metric              │           Value             │           Note              │                     │
│   ├─────────────────────────────┼─────────────────────────────┼─────────────────────────────┤                     │
│   │   Dev EER                   │           3.5%              │   Validation performance    │                     │
│   │   Eval EER                  │           5.37%             │   Test performance          │                     │
│   │   minDCF (19x)              │           0.2443            │   Detection cost            │                     │
│   │   Total Parameters          │           ~5M               │   Trainable params          │                     │
│   │   Feature Disk Space        │           ~132 GB           │   WavLM + SSPS              │                     │
│   │   Training Time             │           ~4 hours          │   100 epochs max            │                     │
│   └─────────────────────────────┴─────────────────────────────┴─────────────────────────────┘                     │
│                                                                                                                   │
└───────────────────────────────────────────────────────────────────────────────────────────────────────────────────┘
